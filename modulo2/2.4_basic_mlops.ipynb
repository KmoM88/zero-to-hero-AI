{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0a34e0",
   "metadata": {},
   "source": [
    "# 2.4 Introduction to MLOps: Model and Experiment Versioning\n",
    "\n",
    "MLOps (Machine Learning Operations) is a set of practices that aims to streamline the deployment, monitoring, and management of machine learning models in production environments. One of the key aspects of MLOps is **versioning**â€”tracking changes to models, datasets, and experiments to ensure reproducibility and collaboration.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the motivation and need for MLOps in professional environments.\n",
    "- Learn about model and experiment versioning techniques.\n",
    "- Explore popular tools and architectures used in real-world MLOps workflows.\n",
    "- Compare different approaches and discuss their pros and cons.\n",
    "- Implement basic versioning using open-source tools.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d68f85",
   "metadata": {},
   "source": [
    "## Why MLOps and Versioning?\n",
    "\n",
    "In professional environments, machine learning projects involve multiple stakeholders, frequent changes, and the need for reproducibility. Without proper versioning, it is difficult to:\n",
    "\n",
    "- Track which data, code, and parameters produced a given model\n",
    "\n",
    "- Collaborate across teams\n",
    "\n",
    "- Reproduce results\n",
    "\n",
    "- Deploy and monitor models reliably\n",
    "\n",
    "\n",
    "![MLOps Lifecycle](https://ml-ops.org/img/ml-engineering.jpg)\n",
    "\n",
    "*Figure: The MLOps lifecycle covers data, code, model, and deployment versioning*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702ba2b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Concepts in MLOps Versioning\n",
    "\n",
    "\n",
    "- **Model Versioning**: Tracking different versions of trained models, including their parameters, code, and metadata.\n",
    "- **Experiment Tracking**: Logging hyperparameters, metrics, and artifacts for each experiment run.\n",
    "- **Data Versioning**: Ensuring the exact dataset used for training/testing is tracked and reproducible.\n",
    "\n",
    "These concepts are essential for reproducibility, auditing, and collaboration in real-world ML projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f4b6b",
   "metadata": {},
   "source": [
    "## Real-World MLOps Architectures and Tools\n",
    "\n",
    "\n",
    "Professional MLOps workflows use a combination of tools and platforms to manage versioning, deployment, and monitoring. Common architectures include:\n",
    "\n",
    "\n",
    "- **Local Development + Git + MLflow/DVC**: Suitable for small teams and research projects.\n",
    "- **Cloud Platforms (AWS SageMaker, Azure ML, GCP Vertex AI)**: Provide integrated experiment tracking, model registry, and deployment.\n",
    "- **Hybrid Solutions**: Combine open-source tools (MLflow, DVC, Kubeflow) with cloud storage and CI/CD pipelines.\n",
    "\n",
    "| Tool         | Model Versioning | Experiment Tracking | Data Versioning | Deployment | Notes |\n",
    "|--------------|------------------|--------------------|-----------------|-----------|-------|\n",
    "| MLflow       | Yes              | Yes                | Limited         | Yes       | Popular, open-source |\n",
    "| DVC          | Yes              | Limited            | Yes             | No        | Git-based, open-source |\n",
    "| Kubeflow     | Yes              | Yes                | Yes             | Yes       | Kubernetes-native |\n",
    "| SageMaker    | Yes              | Yes                | Yes             | Yes       | AWS cloud |\n",
    "| Azure ML     | Yes              | Yes                | Yes             | Yes       | Azure cloud |\n",
    "| Vertex AI    | Yes              | Yes                | Yes             | Yes       | GCP cloud |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdcc030",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example: Experiment Tracking and Model Versioning with MLflow\n",
    "\n",
    "\n",
    "[MLflow](https://mlflow.org/) is a popular open-source platform for managing the ML lifecycle. It provides tools for experiment tracking, model registry, and deployment.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1. Log parameters, metrics, and artifacts for each experiment run.\n",
    "2. Register models in the MLflow Model Registry.\n",
    "3. Deploy models to production from the registry.\n",
    "\n",
    "![MLflow Architecture](https://mlflow.org/docs/2.7.0/_images/mlflow-overview.png)\n",
    "\n",
    "*Figure: MLflow architecture for experiment tracking and model versioning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac5197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model with accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Example: MLflow experiment tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_example = X_train[:2]  # Use a small batch for input example\n",
    "\n",
    "with mlflow.start_run():\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    mlflow.log_param('n_estimators', 100)\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    mlflow.sklearn.log_model(clf, name='model', input_example=input_example)\n",
    "    print(f'Logged model with accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f739676",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example: Data Versioning with DVC\n",
    "\n",
    "\n",
    "[DVC](https://dvc.org/) (Data Version Control) is an open-source tool for versioning datasets and models, built on top of Git. It enables reproducible pipelines and collaborative ML development.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1. Track datasets and model files with DVC commands.\n",
    "2. Store large files in remote storage (S3, GCS, etc.).\n",
    "3. Share and reproduce experiments across teams.\n",
    "\n",
    "![DVC Architecture](https://dvc.org/studio-architecture-diagram-722d060ac956da93c0839ddc736a27a0.svg)\n",
    "\n",
    "*Figure: DVC architecture for data and model versioning*\n",
    "\n",
    "\n",
    "**Comparison:**\n",
    "\n",
    "- MLflow focuses on experiment tracking and model registry.\n",
    "- DVC specializes in data and pipeline versioning.\n",
    "- Both can be integrated for end-to-end MLOps workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DVC commands for data and model versioning\n",
    "!dvc init\n",
    "!dvc add data/dataset.csv\n",
    "!git add data/dataset.csv.dvc .gitignore\n",
    "!git commit -m \"Track dataset with DVC\"\n",
    "!dvc remote add -d myremote s3://mybucket/dvcstore\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312f1bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Practical Recommendations\n",
    "\n",
    "- Use experiment tracking tools (MLflow, SageMaker, Azure ML) to log parameters, metrics, and artifacts.\n",
    "- Version datasets and models with DVC or cloud-native solutions.\n",
    "- Register and deploy models using model registries for traceability.\n",
    "- Integrate CI/CD pipelines for automated testing and deployment.\n",
    "- Choose tools and architectures based on team size, project scale, and compliance needs.\n",
    "\n",
    "**Professional Tip:**\n",
    "- Combine MLflow (experiment/model tracking) with DVC (data/pipeline versioning) for robust, reproducible workflows.\n",
    "- For enterprise projects, leverage cloud platforms for scalability and security.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
